{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcbd4f1",
   "metadata": {},
   "source": [
    "2-1. Nate 뉴스기사 제목 스크래핑하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be169d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://news.nate.com/recent?mid=n0100\n",
    "# 최신뉴스, 정치 , 경제, 사회, 세계, IT/과학 \n",
    "# 6개의 섹션의 뉴스를 출력하는 함수를 생성하여 스크래핑 하기\n",
    "\n",
    "# Image, 기사제목, 기사링크\n",
    "\n",
    "# 뉴스기사의 Image를 출력 하세요 \n",
    "# 1) Image의 도메인이름이 포함된 경로와 src 속성의 경로를 합치려면 urljoin 함수를 사용하세요.\n",
    "#     from urllib.parse import urljoin\n",
    "    \n",
    "#     url = ‘https://news.nate.com/recent?mid=n0100’\n",
    "#     src=’ //thumbnews.nateimg.co.kr/news90///news.nateimg.co.kr/orgImg/na/2025/07/23/7408335_high.jpg’\n",
    "\n",
    "# 2) Image 출력은 Image 클래스와 display 함수를 사용하세요.\n",
    "#     from IPython.display import Image, display\n",
    "\n",
    "# 3) img 엘리먼트의 존재 여부를 체크하신 후에 src 속성의 이미지를 경로를 추출하기\n",
    "#   => Image 가 없는 뉴스도 있기 때문에 \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#요청헤더\n",
    "req_header = {\n",
    "\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\" \n",
    "}\n",
    "section_dict = {'최신뉴스':'recent?mid=n0100','정치':'section?mid=n0200','경제':'section?mid=n0300',\n",
    "                '사회':'section?mid=n0400','세계':'section?mid=n0500','IT/과학':'section?mid=n0600'}\n",
    "\n",
    "\n",
    "\n",
    "def print_news_image(section_name):\n",
    "    sid = section_dict[section_name]\n",
    "    url = f'https://news.nate.com/{sid}'\n",
    "    #응답 엔코딩 헤더 설정\n",
    "    res = requests.get(url,headers=req_header)\n",
    "    res.encoding = 'euc-kr'\n",
    "    \n",
    "    if res.ok:\n",
    "        html = res.text\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "\n",
    "        a_tags = soup.select(\"div.mlt01 a[href*='//news.nate.com/view/']\")\n",
    "        #3) img 엘리먼트의 존재 여부를 체크\n",
    "        for a_tag in a_tags: #img_tag의 타입은 Tag <img>\n",
    "            #Title추출\n",
    "            h2_tags = a_tag.select_one(\"span.tb h2.tit\")\n",
    "            \n",
    "            print(f'기사제목 : {h2_tags.text}')\n",
    "\n",
    "            img_tags = a_tag.select(\"img[src*='//thumbnews.nateimg.co.kr/news90']\")\n",
    "            for img_tag in img_tags:\n",
    "                if img_tag:\n",
    "                    img_url = img_tag['src']\n",
    "                    #1) Image의 도메인이름이 포함된 경로와 src 속성의 경로를 합치려면 urljoin 함수를 사용하세요.\n",
    "                    join_url = urljoin(url,img_url) #기준(base) URL과 상대(relative) URL을 합쳐 절대 URL을 생성\n",
    "\n",
    "                    print(f'기사링크 : {join_url}')\n",
    "                    #2) Image 출력은 Image 클래스와 display 함수를 사용\n",
    "                    print(f'Image : ')\n",
    "                    display(Image(join_url))\n",
    "                else :\n",
    "                    print(\"이미지를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    else:\n",
    "        print(f'Error Code = {res.status_code}')\n",
    "\n",
    "for section in section_dict:\n",
    "    print(f'========={section} 입니다.=========')\n",
    "    print_news_image(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9062a",
   "metadata": {},
   "source": [
    "2-2. 하나의 네이버 웹툰과 1개의 회차에 대한 Image 다운로드 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 웹툰의 '일렉시드' 만화 341회를 다운로드 하였습니다.\n",
      "img\\일렉시드\\341에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# :  하나의 웹툰의 제목(title)과 회차번호(no),회차의URL(url) 을 입력으로 받는 함수를 선언합니다. \n",
    "#    def download_one_episode(title,no,url):\n",
    "\n",
    "# 아래와 같이 호출합니다.\n",
    "# download_one_episode('일렉시드',341,'https://comic.naver.com/webtoon/detail?titleId=717481&no=341&week=wed')\n",
    "\n",
    "# img\\일렉시드\\341 디렉토리가 생성되며 , \n",
    "# 그 디렉토리 아래에 웹툰 image들이 다운로드 되도록 해주세요.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def download_one_episode(title,no,url):\n",
    "    imgdir_name = os.path.join('img', title, str(no))\n",
    "    req_header = {'referer': url}\n",
    "\n",
    "    # 이미지 저장 폴더가 없으면 생성\n",
    "    os.makedirs(imgdir_name, exist_ok = True)\n",
    "    res = requests.get(url)\n",
    "    if not res.ok:\n",
    "        print(f'Error Code = {res.status_code}')\n",
    "        exit()\n",
    "    # 이미지 URL 추출\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    img_url_list = [img_tag['src'] for img_tag in soup.select(\"img[src *= IMAG01]\")]\n",
    "    #print(img_url_list)\n",
    "    #이미지 다운로드\n",
    "    for img_url in img_url_list:\n",
    "        res = requests.get(img_url, headers=req_header)\n",
    "        if res.ok:\n",
    "            img_data = res.content\n",
    "            file_path = os.path.join(imgdir_name, os.path.basename(img_url))\n",
    "            with open(file_path, 'wb') as file:\n",
    "                #print(f'Wrting to {file_path} ({len(img_data):,} bytes)')\n",
    "                file.write(img_data)\n",
    "\n",
    "        else:\n",
    "            print(f'Error Code = {res.status_code}')\n",
    "    print(f\"네이버 웹툰의 '{title}' 만화 {no}회를 다운로드 하였습니다.\")\n",
    "    print(f'{imgdir_name} 폴더에 있습니다.')\n",
    "#호출\n",
    "download_one_episode('일렉시드',341,'https://comic.naver.com/webtoon/detail?titleId=717481&no=341&week=wed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
